{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Mining API query testing\n",
    "\n",
    "Load the target datafile, and see how the query results work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload local package definitions for each cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/grequests.py:22: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.contrib.pyopenssl (/usr/local/lib/python3.8/site-packages/urllib3/contrib/pyopenssl.py)']. \n",
      "  curious_george.patch_all(thread=False, select=False)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import requests\n",
    "import grequests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from arg_mine import DATA_DIR\n",
    "from arg_mine.data.loaders import get_gdelt_df\n",
    "from arg_mine.api import classify, auth, session, errors\n",
    "from arg_mine import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the env variables to get the API key\n",
    "user_id, api_key = auth.load_auth_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>headline_image_url</th>\n",
       "      <th>content_url</th>\n",
       "      <th>labeled_argument</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200115111500</td>\n",
       "      <td>Liberal MPs back Science Minister Karen Andrew...</td>\n",
       "      <td>https://static.ffx.io/images/$zoom_0.2627%2C$m...</td>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>the science in her interview with The Age and...</td>\n",
       "      <td>2020-01-15 11:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200117184500</td>\n",
       "      <td>Several crowd-pullers on day two of KLF</td>\n",
       "      <td>https://www.thehindu.com/news/cities/kozhikode...</td>\n",
       "      <td>https://www.thehindu.com/news/cities/kozhikode...</td>\n",
       "      <td>Guha, who talked about patriotism and jingois...</td>\n",
       "      <td>2020-01-17 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200106233000</td>\n",
       "      <td>Seven arrested after gas rig protest</td>\n",
       "      <td>https://www.stourbridgenews.co.uk/resources/im...</td>\n",
       "      <td>https://www.stourbridgenews.co.uk/news/nationa...</td>\n",
       "      <td>three demands for the Scottish and UK Governm...</td>\n",
       "      <td>2020-01-06 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200101111500</td>\n",
       "      <td>Australia sending aid to wildfire towns as dea...</td>\n",
       "      <td>https://bloximages.newyork1.vip.townnews.com/h...</td>\n",
       "      <td>https://www.heraldmailmedia.com/news/nation/au...</td>\n",
       "      <td>this season the worst on record and reignited ...</td>\n",
       "      <td>2020-01-01 11:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200107101500</td>\n",
       "      <td>A hot, dry country caught between fire and a c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://global.chinadaily.com.cn/a/202001/07/WS...</td>\n",
       "      <td>, which is burned to generate electricity, wit...</td>\n",
       "      <td>2020-01-07 10:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime                                              title  \\\n",
       "0  20200115111500  Liberal MPs back Science Minister Karen Andrew...   \n",
       "1  20200117184500            Several crowd-pullers on day two of KLF   \n",
       "2  20200106233000               Seven arrested after gas rig protest   \n",
       "3  20200101111500  Australia sending aid to wildfire towns as dea...   \n",
       "4  20200107101500  A hot, dry country caught between fire and a c...   \n",
       "\n",
       "                                  headline_image_url  \\\n",
       "0  https://static.ffx.io/images/$zoom_0.2627%2C$m...   \n",
       "1  https://www.thehindu.com/news/cities/kozhikode...   \n",
       "2  https://www.stourbridgenews.co.uk/resources/im...   \n",
       "3  https://bloximages.newyork1.vip.townnews.com/h...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         content_url  \\\n",
       "0  https://www.smh.com.au/politics/federal/libera...   \n",
       "1  https://www.thehindu.com/news/cities/kozhikode...   \n",
       "2  https://www.stourbridgenews.co.uk/news/nationa...   \n",
       "3  https://www.heraldmailmedia.com/news/nation/au...   \n",
       "4  http://global.chinadaily.com.cn/a/202001/07/WS...   \n",
       "\n",
       "                                    labeled_argument           timestamp  \n",
       "0   the science in her interview with The Age and... 2020-01-15 11:15:00  \n",
       "1   Guha, who talked about patriotism and jingois... 2020-01-17 18:45:00  \n",
       "2   three demands for the Scottish and UK Governm... 2020-01-06 23:30:00  \n",
       "3  this season the worst on record and reignited ... 2020-01-01 11:15:00  \n",
       "4  , which is burned to generate electricity, wit... 2020-01-07 10:15:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_datapath = os.path.join(DATA_DIR, \"raw\", \"2020-climate-change-narrative\")\n",
    "csv_filepath = os.path.join(csv_datapath, \"WebNewsEnglishSnippets.2020.csv\")\n",
    "\n",
    "url_df = get_gdelt_df(csv_filepath)\n",
    "url_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the `classify` request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = url_df.iloc[0].content_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFY_BASE_URL = \"https://api.argumentsearch.com/en/classify\"\n",
    "timeout = 5\n",
    "\n",
    "topic = \"climate change\"\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"topic\": topic,\n",
    "    \"userID\": user_id,\n",
    "    \"apiKey\": api_key,\n",
    "    \"targetUrl\": url,\n",
    "    \"topicRelevance\": \"word2vec\",\n",
    "    \"predictStance\": True,\n",
    "    \"computeAttention\": True,\n",
    "    \"showOnlyArguments\": False,\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    CLASSIFY_BASE_URL,\n",
    "    json=payload,\n",
    "    timeout=timeout,\n",
    ")\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'sentences'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = response.json()\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try a single URL\n",
    "Get the doc and sentence objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = classify.classify_url_sentences(topic, url_df.content_url.values[0], user_id, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifiedSentence(url='https://www.smh.com.au/politics/federal/liberals-speak-out-to-back-science-minister-on-climate-change-action-20200115-p53rs1.html', doc_id='657f9dd95eb97597e34d0c05b5a93ba6', topic='climate change', sentence_id='da903878c62343fb482bfad67a7523f1', argument_confidence=0.9836708698421717, argument_label='argument', sentence_original='Mr Morrison said Ms Andrews had \"well set out\" the government policy and signalled again that he would bring forward future policies to adapt to a changing climate while also doing more to reduce greenhouse gas emissions.', sentence_preprocessed='Mr Morrison said Ms Andrews had \"well set out\" the government policy and signalled again that he would bring forward future policies to adapt to a changing climate while also doing more to reduce greenhouse gas emissions.', sort_confidence=0.9907711706754092, stance_confidence=0.9978714715086467, stance_label='pro')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.ClassifiedSentence.from_dict(url, topic, response['sentences'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'argumentConfidence': 0.9836708698421717,\n",
       " 'argumentLabel': 'argument',\n",
       " 'sentenceOriginal': 'Mr Morrison said Ms Andrews had \"well set out\" the government policy and signalled again that he would bring forward future policies to adapt to a changing climate while also doing more to reduce greenhouse gas emissions.',\n",
       " 'sentencePreprocessed': 'Mr Morrison said Ms Andrews had \"well set out\" the government policy and signalled again that he would bring forward future policies to adapt to a changing climate while also doing more to reduce greenhouse gas emissions.',\n",
       " 'sortConfidence': 0.9907711706754092,\n",
       " 'stanceConfidence': 0.9978714715086467,\n",
       " 'stanceLabel': 'pro'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator.\n"
     ]
    }
   ],
   "source": [
    "# good example of a link that is no longer valid\n",
    "url = url_df.content_url.values[3]\n",
    "try: \n",
    "    response = classify.classify_url_sentences(topic, url, user_id, api_key)\n",
    "except errors.Refused as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a batch of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108459,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df.content_url.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:2020-07-02 17:52:12,472:arg_mine.api.classify: Attempting url 1 of 20\n",
      "DEBUG:2020-07-02 17:52:14,023:arg_mine.api.classify: Attempting url 2 of 20\n",
      "DEBUG:2020-07-02 17:52:15,526:arg_mine.api.classify: Attempting url 3 of 20\n",
      "DEBUG:2020-07-02 17:52:17,162:arg_mine.api.classify: Attempting url 4 of 20\n",
      "WARNING:2020-07-02 17:52:17,746:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.heraldmailmedia.com/news/nation/australia-sending-aid-to-wildfire-towns-as-death-toll-rises/article_883fa793-6c0a-547e-8f77-b5964f1d7182.html\n",
      "DEBUG:2020-07-02 17:52:17,748:arg_mine.api.classify: Attempting url 5 of 20\n",
      "DEBUG:2020-07-02 17:52:19,338:arg_mine.api.classify: Attempting url 6 of 20\n",
      "DEBUG:2020-07-02 17:52:21,553:arg_mine.api.classify: Attempting url 7 of 20\n",
      "WARNING:2020-07-02 17:52:21,852:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.seattlepi.com/news/world/article/Cooler-weather-brings-respite-in-Australian-14950114.php\n",
      "DEBUG:2020-07-02 17:52:21,853:arg_mine.api.classify: Attempting url 8 of 20\n",
      "WARNING:2020-07-02 17:52:23,332:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.airdrietoday.com/national-business/starbucks-goals-for-sustainability-will-require-significant-consumer-buy-in-2037947\n",
      "DEBUG:2020-07-02 17:52:23,334:arg_mine.api.classify: Attempting url 9 of 20\n",
      "WARNING:2020-07-02 17:52:24,719:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.heraldbulletin.com/news/nation_world/davos-chief-welcomes-views-of-trump-greta-thunberg-at-forum/article_24dbb151-7132-5c48-a7df-c13b67004ec0.html\n",
      "DEBUG:2020-07-02 17:52:24,721:arg_mine.api.classify: Attempting url 10 of 20\n",
      "DEBUG:2020-07-02 17:52:26,161:arg_mine.api.classify: Attempting url 11 of 20\n",
      "DEBUG:2020-07-02 17:52:27,739:arg_mine.api.classify: Attempting url 12 of 20\n",
      "DEBUG:2020-07-02 17:52:28,905:arg_mine.api.classify: Attempting url 13 of 20\n",
      "DEBUG:2020-07-02 17:52:29,999:arg_mine.api.classify: Attempting url 14 of 20\n",
      "WARNING:2020-07-02 17:52:30,907:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://ravallirepublic.com/news/local/article_cb291465-d430-5477-8b41-1bedda9beaea.html\n",
      "DEBUG:2020-07-02 17:52:30,909:arg_mine.api.classify: Attempting url 15 of 20\n",
      "WARNING:2020-07-02 17:52:33,063:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.caledonianrecord.com/opinion/columns/shawn-shouldice-small-business-owners-prepare-to-dodge-bullets-during/article_9f1b6399-7ca9-59bc-8788-b4d05ec5825c.html\n",
      "DEBUG:2020-07-02 17:52:33,065:arg_mine.api.classify: Attempting url 16 of 20\n",
      "DEBUG:2020-07-02 17:52:34,590:arg_mine.api.classify: Attempting url 17 of 20\n",
      "WARNING:2020-07-02 17:52:35,284:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.nsnews.com/trudeau-meets-pallister-and-the-meng-hearing-in-the-news-for-jan-20-1.24056357\n",
      "DEBUG:2020-07-02 17:52:35,286:arg_mine.api.classify: Attempting url 18 of 20\n",
      "DEBUG:2020-07-02 17:52:36,919:arg_mine.api.classify: Attempting url 19 of 20\n",
      "DEBUG:2020-07-02 17:52:38,304:arg_mine.api.classify: Attempting url 20 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration took 28.3 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "doc_list, sentence_list, refused_doc_list = classify.collect_sentences_by_topic(topic, url_df.content_url.values[:20])\n",
    "\n",
    "print(\"iteration took {:.3} s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.heraldmailmedia.com/news/nation/australia-sending-aid-to-wildfire-towns-as-death-toll-rises/article_883fa793-6c0a-547e-8f77-b5964f1d7182.html',\n",
       " 'https://www.seattlepi.com/news/world/article/Cooler-weather-brings-respite-in-Australian-14950114.php',\n",
       " 'https://www.airdrietoday.com/national-business/starbucks-goals-for-sustainability-will-require-significant-consumer-buy-in-2037947',\n",
       " 'https://www.heraldbulletin.com/news/nation_world/davos-chief-welcomes-views-of-trump-greta-thunberg-at-forum/article_24dbb151-7132-5c48-a7df-c13b67004ec0.html',\n",
       " 'https://ravallirepublic.com/news/local/article_cb291465-d430-5477-8b41-1bedda9beaea.html',\n",
       " 'https://www.caledonianrecord.com/opinion/columns/shawn-shouldice-small-business-owners-prepare-to-dodge-bullets-during/article_9f1b6399-7ca9-59bc-8788-b4d05ec5825c.html',\n",
       " 'https://www.nsnews.com/trudeau-meets-pallister-and-the-meng-hearing-in-the-news-for-jan-20-1.24056357']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(refused_doc_list))\n",
    "refused_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try concurrent requests with grequest\n",
    "\n",
    "`grequest` does concurrent threaded requests, but has memory issues for long lists. We can chunk the async requests and write the outputs to storage to avoid this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:2020-07-02 17:52:40,871:arg_mine.api.classify: >>>> starting doc extraction\n",
      "DEBUG:2020-07-02 17:52:58,853:arg_mine.api.classify: iteration 0 took 17.980 s (10 docs)\n",
      "DEBUG:2020-07-02 17:53:14,431:arg_mine.api.classify: iteration 1 took 15.577 s (10 docs)\n",
      "DEBUG:2020-07-02 17:53:14,432:arg_mine.api.classify: 20 URLs took 33.561 s\n"
     ]
    }
   ],
   "source": [
    "responses = classify.fetch_concurrent(topic, url_list = url_df.content_url.values[:20], chunk_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:2020-07-02 17:53:14,465:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,469:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,470:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,470:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,473:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,474:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 17:53:14,476:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n"
     ]
    }
   ],
   "source": [
    "docs_df, sentences_df, missing_urls = classify.process_responses(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label the sentences as GT arguments\n",
    "The given snippit contains context surrounding the given identified key phrase. Tokenizing the phrase will not work.\n",
    "It is still unclear on whether or not the GT data can be claimed to be an argument; likely not.\n",
    "\n",
    "> This final dataset covers worldwide English language online news coverage 2015-2020 mentioning \"climate change\" OR \"global warming\" OR \"climate crisis\" OR \"greenhouse gas\" OR \"greenhouse gases\" OR \"carbon tax\" totaling 6.3 million articles. [...]  \n",
    ">Most importantly, for each match, a short snippet is shown that shows the first instance of one of the climate change phrases above in the article with the 100 characters before and after the appearance, truncated to the nearest word (if the 100th character before or after the phrase appears in the middle of a word, the window will be shrunk to the closest full word). Note that in the majority of cases the first match in the article is selected, but sometimes due to the nature of the finite automaton used to generate the snippets, a later match may be chosen from the article if it allows for a larger context window under certain circumstances.  \n",
    ">Using a window of 100 characters before and after the match allows for brief non-consumptive snippets that show the context of the match and allow a better understanding of whether the article's mention of climate change was a cursory mention or central to the story and the argument, evidence  and context of the narrative within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extracted sentences\n",
    "target_dir = \"gdelt-climate-change-docs\"\n",
    "in_data_path = os.path.join(DATA_DIR, \"processed\", target_dir)\n",
    "\n",
    "docs_filename = \"gdelt_2020_docs.csv\"\n",
    "sentences_filename = \"gdelt_2020_sentences.csv\"\n",
    "\n",
    "# load the files into dataframes\n",
    "docs_df = pd.read_csv(os.path.join(in_data_path, docs_filename))\n",
    "sentences_df = pd.read_csv(os.path.join(in_data_path, sentences_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing this out to use for parsing later\n",
    "keyword_list = [\n",
    "    \"climate change\",\n",
    "    \"global warming\",\n",
    "    \"climate crisis\",\n",
    "    \"greenhouse gas\",\n",
    "    \"greenhouse gases\",\n",
    "    \"carbon tax\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods for finding the GT argument sentences we extract\n",
    "\n",
    "def match_doc_id(url, docs_df):\n",
    "    \"\"\"Get the document id from the ground truth dataset\"\"\"\n",
    "    return docs_df[url == docs_df['url']]['doc_id'].iloc[0]\n",
    "\n",
    "def get_doc_sentences(doc_id, sentences_df):\n",
    "    \"\"\"Return all sentences for a given doc_id\"\"\"\n",
    "    return sentences_df[sentences_df.doc_id == doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = match_doc_id(url_df.iloc[0]['content_url'], docs_df)\n",
    "doc_sentences = get_doc_sentences(doc_id, sentences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['has_labeled_arg'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'doc_id', 'topic', 'sentence_id', 'argument_confidence',\n",
       "       'argument_label', 'sentence_original', 'sentence_preprocessed',\n",
       "       'sort_confidence', 'stance_confidence', 'stance_label',\n",
       "       'has_labeled_arg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26    4a2fcf5b4ca0e45bcae7fcc6af5e2cd6\n",
      "Name: sentence_id, dtype: object\n",
      "3    9eac4f301da33af0eaf7e5a4b1a5c759\n",
      "Name: sentence_id, dtype: object\n",
      "23    e3496a47bcad630aea1f078b5202cd43\n",
      "Name: sentence_id, dtype: object\n",
      "12.3 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "content_url = url_df.iloc[0]\n",
    "snippit = url_df['labeled_argument'][0]\n",
    "doc_id = match_doc_id(content_url['content_url'], docs_df)\n",
    "doc_sentences = get_doc_sentences(doc_id, sentences_df)\n",
    "\n",
    "# tokenize the GT argument\n",
    "arg_tokens = snippit.split(\".\") if isinstance(snippit, str) else None\n",
    "arg_tokens = [s.strip() for s in arg_tokens]\n",
    "\n",
    "for token in arg_tokens:\n",
    "    matches = doc_sentences[doc_sentences.sentence_original.str.contains(token, na=False)]['sentence_id']\n",
    "    print(matches)\n",
    "    # only look at the first match\n",
    "    sentences_df.loc[sentences_df['sentence_id'] == matches.values[0], 'has_labeled_arg'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Australians want us to get on with the job of meeting our'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3      True\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23     True\n",
       "24    False\n",
       "25    False\n",
       "26     True\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30    False\n",
       "31    False\n",
       "32    False\n",
       "33    False\n",
       "34    False\n",
       "35    False\n",
       "36    False\n",
       "Name: has_labeled_arg, dtype: bool"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.loc[sentences_df.doc_id == doc_id]['has_labeled_arg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df_crop = url_df[url_df['content_url'].isin(docs_df.url.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "for i, url_row in url_df_crop.iterrows():\n",
    "    if i == 0:\n",
    "        print(type(url_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arg_mine.data import labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                                                 20200101004500\n",
       "title                 Norman Chad: Looking back at the last two deca...\n",
       "headline_image_url                                                  NaN\n",
       "content_url           https://www.spokesman.com/stories/2019/dec/31/...\n",
       "labeled_argument      your left for 3 hours talking up launch angle ...\n",
       "timestamp                                           2020-01-01 00:45:00\n",
       "Name: 49, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:2020-07-02 21:45:30,507:arg_mine.api.classify: No matches found for token in doc 511e6394e836de229627483715722598: 'your left for 3 hours talking up launch angle and which way Wisconsin is leaning? Science denial: What planet are flat earthers, anti-vaxxers and climate change rebutters living on? And is e=mc² suddenly in question? Streaming services: Believe it or not, you can have too many choices'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>argument_confidence</th>\n",
       "      <th>argument_label</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>sentence_preprocessed</th>\n",
       "      <th>sort_confidence</th>\n",
       "      <th>stance_confidence</th>\n",
       "      <th>stance_label</th>\n",
       "      <th>has_labeled_arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>657f9dd95eb97597e34d0c05b5a93ba6</td>\n",
       "      <td>climate change</td>\n",
       "      <td>da903878c62343fb482bfad67a7523f1</td>\n",
       "      <td>0.983671</td>\n",
       "      <td>argument</td>\n",
       "      <td>Mr Morrison said Ms Andrews had \"well set out\"...</td>\n",
       "      <td>Mr Morrison said Ms Andrews had \"well set out\"...</td>\n",
       "      <td>0.990771</td>\n",
       "      <td>0.997871</td>\n",
       "      <td>pro</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>657f9dd95eb97597e34d0c05b5a93ba6</td>\n",
       "      <td>climate change</td>\n",
       "      <td>194995c09a1bbb4fa2f1d53dabc88f76</td>\n",
       "      <td>0.950217</td>\n",
       "      <td>argument</td>\n",
       "      <td>\"What I have been seeking to stress, particula...</td>\n",
       "      <td>\"What I have been seeking to stress, particula...</td>\n",
       "      <td>0.970347</td>\n",
       "      <td>0.990477</td>\n",
       "      <td>pro</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>657f9dd95eb97597e34d0c05b5a93ba6</td>\n",
       "      <td>climate change</td>\n",
       "      <td>7582076e5fbb0316c7cff50bfea50857</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>argument</td>\n",
       "      <td>Mr Kelly said the only \"denial\" he had seen wa...</td>\n",
       "      <td>Mr Kelly said the only \"denial\" he had seen wa...</td>\n",
       "      <td>0.889054</td>\n",
       "      <td>0.845181</td>\n",
       "      <td>contra</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>657f9dd95eb97597e34d0c05b5a93ba6</td>\n",
       "      <td>climate change</td>\n",
       "      <td>9eac4f301da33af0eaf7e5a4b1a5c759</td>\n",
       "      <td>0.774244</td>\n",
       "      <td>argument</td>\n",
       "      <td>\"Overwhelmingly, Australians accept the scienc...</td>\n",
       "      <td>\"Overwhelmingly, Australians accept the scienc...</td>\n",
       "      <td>0.879241</td>\n",
       "      <td>0.984239</td>\n",
       "      <td>pro</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.smh.com.au/politics/federal/libera...</td>\n",
       "      <td>657f9dd95eb97597e34d0c05b5a93ba6</td>\n",
       "      <td>climate change</td>\n",
       "      <td>cb25d9b5f07e95fa139f19951515c0e4</td>\n",
       "      <td>0.650039</td>\n",
       "      <td>argument</td>\n",
       "      <td>\"Karen is correct when she says every second s...</td>\n",
       "      <td>\"Karen is correct when she says every second s...</td>\n",
       "      <td>0.701024</td>\n",
       "      <td>0.752010</td>\n",
       "      <td>contra</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>https://www.spokesman.com/stories/2019/dec/31/...</td>\n",
       "      <td>511e6394e836de229627483715722598</td>\n",
       "      <td>climate change</td>\n",
       "      <td>b127099c71415d532da3a26ed73eb041</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>no argument</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>https://www.spokesman.com/stories/2019/dec/31/...</td>\n",
       "      <td>511e6394e836de229627483715722598</td>\n",
       "      <td>climate change</td>\n",
       "      <td>a1452a6833e0f4e61333a3b6cfeb627e</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>no argument</td>\n",
       "      <td>Subscribe to the sports newsletter</td>\n",
       "      <td>Subscribe to the sports newsletter</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>https://www.spokesman.com/stories/2019/dec/31/...</td>\n",
       "      <td>511e6394e836de229627483715722598</td>\n",
       "      <td>climate change</td>\n",
       "      <td>fa3b543024a35670b52e3d5837301443</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>no argument</td>\n",
       "      <td>Do I like toast?</td>\n",
       "      <td>Do I like toast?</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>https://www.spokesman.com/stories/2019/dec/31/...</td>\n",
       "      <td>511e6394e836de229627483715722598</td>\n",
       "      <td>climate change</td>\n",
       "      <td>d29e17970a473ba8a812c0f95ba065dd</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>no argument</td>\n",
       "      <td>Just email asktheslouch@aol.com and, if your q...</td>\n",
       "      <td>Just email asktheslouch@aol.com and, if your q...</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>https://www.spokesman.com/stories/2019/dec/31/...</td>\n",
       "      <td>511e6394e836de229627483715722598</td>\n",
       "      <td>climate change</td>\n",
       "      <td>8cd4cdb13cceeee25127bb4a5c40714d</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>no argument</td>\n",
       "      <td>Get the day’s top sports headlines and breakin...</td>\n",
       "      <td>Get the day’s top sports headlines and breakin...</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://www.smh.com.au/politics/federal/libera...   \n",
       "1     https://www.smh.com.au/politics/federal/libera...   \n",
       "2     https://www.smh.com.au/politics/federal/libera...   \n",
       "3     https://www.smh.com.au/politics/federal/libera...   \n",
       "4     https://www.smh.com.au/politics/federal/libera...   \n",
       "...                                                 ...   \n",
       "1486  https://www.spokesman.com/stories/2019/dec/31/...   \n",
       "1487  https://www.spokesman.com/stories/2019/dec/31/...   \n",
       "1488  https://www.spokesman.com/stories/2019/dec/31/...   \n",
       "1489  https://www.spokesman.com/stories/2019/dec/31/...   \n",
       "1490  https://www.spokesman.com/stories/2019/dec/31/...   \n",
       "\n",
       "                                doc_id           topic  \\\n",
       "0     657f9dd95eb97597e34d0c05b5a93ba6  climate change   \n",
       "1     657f9dd95eb97597e34d0c05b5a93ba6  climate change   \n",
       "2     657f9dd95eb97597e34d0c05b5a93ba6  climate change   \n",
       "3     657f9dd95eb97597e34d0c05b5a93ba6  climate change   \n",
       "4     657f9dd95eb97597e34d0c05b5a93ba6  climate change   \n",
       "...                                ...             ...   \n",
       "1486  511e6394e836de229627483715722598  climate change   \n",
       "1487  511e6394e836de229627483715722598  climate change   \n",
       "1488  511e6394e836de229627483715722598  climate change   \n",
       "1489  511e6394e836de229627483715722598  climate change   \n",
       "1490  511e6394e836de229627483715722598  climate change   \n",
       "\n",
       "                           sentence_id  argument_confidence argument_label  \\\n",
       "0     da903878c62343fb482bfad67a7523f1             0.983671       argument   \n",
       "1     194995c09a1bbb4fa2f1d53dabc88f76             0.950217       argument   \n",
       "2     7582076e5fbb0316c7cff50bfea50857             0.932927       argument   \n",
       "3     9eac4f301da33af0eaf7e5a4b1a5c759             0.774244       argument   \n",
       "4     cb25d9b5f07e95fa139f19951515c0e4             0.650039       argument   \n",
       "...                                ...                  ...            ...   \n",
       "1486  b127099c71415d532da3a26ed73eb041             0.003481    no argument   \n",
       "1487  a1452a6833e0f4e61333a3b6cfeb627e             0.003417    no argument   \n",
       "1488  fa3b543024a35670b52e3d5837301443             0.003401    no argument   \n",
       "1489  d29e17970a473ba8a812c0f95ba065dd             0.003389    no argument   \n",
       "1490  8cd4cdb13cceeee25127bb4a5c40714d             0.003239    no argument   \n",
       "\n",
       "                                      sentence_original  \\\n",
       "0     Mr Morrison said Ms Andrews had \"well set out\"...   \n",
       "1     \"What I have been seeking to stress, particula...   \n",
       "2     Mr Kelly said the only \"denial\" he had seen wa...   \n",
       "3     \"Overwhelmingly, Australians accept the scienc...   \n",
       "4     \"Karen is correct when she says every second s...   \n",
       "...                                                 ...   \n",
       "1486                                               Yes.   \n",
       "1487                 Subscribe to the sports newsletter   \n",
       "1488                                   Do I like toast?   \n",
       "1489  Just email asktheslouch@aol.com and, if your q...   \n",
       "1490  Get the day’s top sports headlines and breakin...   \n",
       "\n",
       "                                  sentence_preprocessed  sort_confidence  \\\n",
       "0     Mr Morrison said Ms Andrews had \"well set out\"...         0.990771   \n",
       "1     \"What I have been seeking to stress, particula...         0.970347   \n",
       "2     Mr Kelly said the only \"denial\" he had seen wa...         0.889054   \n",
       "3     \"Overwhelmingly, Australians accept the scienc...         0.879241   \n",
       "4     \"Karen is correct when she says every second s...         0.701024   \n",
       "...                                                 ...              ...   \n",
       "1486                                               Yes.         0.003481   \n",
       "1487                 Subscribe to the sports newsletter         0.003417   \n",
       "1488                                   Do I like toast?         0.003401   \n",
       "1489  Just email asktheslouch@aol.com and, if your q...         0.003389   \n",
       "1490  Get the day’s top sports headlines and breakin...         0.003239   \n",
       "\n",
       "      stance_confidence stance_label  has_labeled_arg  \n",
       "0              0.997871          pro            False  \n",
       "1              0.990477          pro            False  \n",
       "2              0.845181       contra            False  \n",
       "3              0.984239          pro             True  \n",
       "4              0.752010       contra            False  \n",
       "...                 ...          ...              ...  \n",
       "1486           0.000000                         False  \n",
       "1487           0.000000                         False  \n",
       "1488           0.000000                         False  \n",
       "1489           0.000000                         False  \n",
       "1490           0.000000                         False  \n",
       "\n",
       "[1491 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelers.label_doc_sentences_with_context(url_row, docs_df, sentences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b4f9cf28ce74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnippit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "tokenize.sent_tokenize(snippit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: sentence_id, dtype: object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your left for 3 hours talking up launch angle and which way Wisconsin is leaning? Science denial: What planet are flat earthers, anti-vaxxers and climate change rebutters living on? And is e=mc² suddenly in question? Streaming services: Believe it or not, you can have too many choices'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2122decd2322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msentences_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_gdelt_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/workspace/arg_mine/data/labelers.py\u001b[0m in \u001b[0;36mlabel_gdelt_sentences\u001b[0;34m(url_df, docs_df, sentences_df)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_df_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# does modification of sentences_df in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mlabel_doc_sentences_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/workspace/arg_mine/data/labelers.py\u001b[0m in \u001b[0;36mlabel_doc_sentences_with_context\u001b[0;34m(url_row, docs_df, sentences_df)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# only look at the first match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msentences_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentences_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'has_labeled_arg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "sentences_df = labelers.label_gdelt_sentences(url_df, docs_df, sentences_df)\n",
    "\n",
    "\n",
    "print(\"labeling took {:0.2f} s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check timing of different approaches\n",
    "\n",
    "Does grequests give us a performance boost?\n",
    "* time serial extraction vs using grequests\n",
    "\n",
    "Does returning all sentences vs just arguments give us a performance hit?\n",
    "* time extraction of 50 articles to see if API times are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:2020-07-02 17:57:12,559:arg_mine.api.classify: Attempting url 1 of 50\n",
      "DEBUG:2020-07-02 17:57:14,422:arg_mine.api.classify: Attempting url 2 of 50\n",
      "DEBUG:2020-07-02 17:57:15,828:arg_mine.api.classify: Attempting url 3 of 50\n",
      "DEBUG:2020-07-02 17:57:17,416:arg_mine.api.classify: Attempting url 4 of 50\n",
      "WARNING:2020-07-02 17:57:18,040:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.heraldmailmedia.com/news/nation/australia-sending-aid-to-wildfire-towns-as-death-toll-rises/article_883fa793-6c0a-547e-8f77-b5964f1d7182.html\n",
      "DEBUG:2020-07-02 17:57:18,041:arg_mine.api.classify: Attempting url 5 of 50\n",
      "DEBUG:2020-07-02 17:57:19,420:arg_mine.api.classify: Attempting url 6 of 50\n",
      "DEBUG:2020-07-02 17:57:20,756:arg_mine.api.classify: Attempting url 7 of 50\n",
      "WARNING:2020-07-02 17:57:21,135:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.seattlepi.com/news/world/article/Cooler-weather-brings-respite-in-Australian-14950114.php\n",
      "DEBUG:2020-07-02 17:57:21,136:arg_mine.api.classify: Attempting url 8 of 50\n",
      "WARNING:2020-07-02 17:57:22,511:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.airdrietoday.com/national-business/starbucks-goals-for-sustainability-will-require-significant-consumer-buy-in-2037947\n",
      "DEBUG:2020-07-02 17:57:22,512:arg_mine.api.classify: Attempting url 9 of 50\n",
      "WARNING:2020-07-02 17:57:24,043:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.heraldbulletin.com/news/nation_world/davos-chief-welcomes-views-of-trump-greta-thunberg-at-forum/article_24dbb151-7132-5c48-a7df-c13b67004ec0.html\n",
      "DEBUG:2020-07-02 17:57:24,044:arg_mine.api.classify: Attempting url 10 of 50\n",
      "DEBUG:2020-07-02 17:57:25,352:arg_mine.api.classify: Attempting url 11 of 50\n",
      "DEBUG:2020-07-02 17:57:26,937:arg_mine.api.classify: Attempting url 12 of 50\n",
      "DEBUG:2020-07-02 17:57:27,945:arg_mine.api.classify: Attempting url 13 of 50\n",
      "DEBUG:2020-07-02 17:57:29,044:arg_mine.api.classify: Attempting url 14 of 50\n",
      "WARNING:2020-07-02 17:57:29,831:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://ravallirepublic.com/news/local/article_cb291465-d430-5477-8b41-1bedda9beaea.html\n",
      "DEBUG:2020-07-02 17:57:29,832:arg_mine.api.classify: Attempting url 15 of 50\n",
      "WARNING:2020-07-02 17:57:31,008:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.caledonianrecord.com/opinion/columns/shawn-shouldice-small-business-owners-prepare-to-dodge-bullets-during/article_9f1b6399-7ca9-59bc-8788-b4d05ec5825c.html\n",
      "DEBUG:2020-07-02 17:57:31,009:arg_mine.api.classify: Attempting url 16 of 50\n",
      "DEBUG:2020-07-02 17:57:32,374:arg_mine.api.classify: Attempting url 17 of 50\n",
      "WARNING:2020-07-02 17:57:33,196:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.nsnews.com/trudeau-meets-pallister-and-the-meng-hearing-in-the-news-for-jan-20-1.24056357\n",
      "DEBUG:2020-07-02 17:57:33,197:arg_mine.api.classify: Attempting url 18 of 50\n",
      "DEBUG:2020-07-02 17:57:34,734:arg_mine.api.classify: Attempting url 19 of 50\n",
      "DEBUG:2020-07-02 17:57:35,967:arg_mine.api.classify: Attempting url 20 of 50\n",
      "DEBUG:2020-07-02 17:57:38,126:arg_mine.api.classify: Attempting url 21 of 50\n",
      "DEBUG:2020-07-02 17:57:38,967:arg_mine.api.classify: Attempting url 22 of 50\n",
      "DEBUG:2020-07-02 17:57:40,134:arg_mine.api.classify: Attempting url 23 of 50\n",
      "DEBUG:2020-07-02 17:57:42,133:arg_mine.api.classify: Attempting url 24 of 50\n",
      "WARNING:2020-07-02 17:57:42,738:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://isp.netscape.com/news/story/0002/20200109/KBN1Z81IM_6\n",
      "DEBUG:2020-07-02 17:57:42,739:arg_mine.api.classify: Attempting url 25 of 50\n",
      "DEBUG:2020-07-02 17:57:44,605:arg_mine.api.classify: Attempting url 26 of 50\n",
      "DEBUG:2020-07-02 17:57:45,955:arg_mine.api.classify: Attempting url 27 of 50\n",
      "DEBUG:2020-07-02 17:57:47,392:arg_mine.api.classify: Attempting url 28 of 50\n",
      "DEBUG:2020-07-02 17:57:49,498:arg_mine.api.classify: Attempting url 29 of 50\n",
      "DEBUG:2020-07-02 17:57:50,687:arg_mine.api.classify: Attempting url 30 of 50\n",
      "DEBUG:2020-07-02 17:57:52,843:arg_mine.api.classify: Attempting url 31 of 50\n",
      "DEBUG:2020-07-02 17:57:54,282:arg_mine.api.classify: Attempting url 32 of 50\n",
      "DEBUG:2020-07-02 17:57:55,364:arg_mine.api.classify: Attempting url 33 of 50\n",
      "WARNING:2020-07-02 17:57:56,262:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://democratherald.com/news/world/climate-change-brexit-divorce-eu-faces-challenges-in/article_242dbfcc-756a-5eeb-b0d4-731f00f905a7.html\n",
      "DEBUG:2020-07-02 17:57:56,263:arg_mine.api.classify: Attempting url 34 of 50\n",
      "DEBUG:2020-07-02 17:57:58,648:arg_mine.api.classify: Attempting url 35 of 50\n",
      "DEBUG:2020-07-02 17:57:59,832:arg_mine.api.classify: Attempting url 36 of 50\n",
      "DEBUG:2020-07-02 17:58:01,044:arg_mine.api.classify: Attempting url 37 of 50\n",
      "WARNING:2020-07-02 17:58:01,762:arg_mine.api.classify: Refused: Refused: 400: Website could not be crawled or returned an empty result. Please contact an administrator., url=https://www.dailyadvance.com/news/world/man-burned-as-huge-wildfire-forms-during-australia-crisis/article_8c6b5e0b-5782-5d02-936a-212b781ce1e8.html\n",
      "DEBUG:2020-07-02 17:58:01,763:arg_mine.api.classify: Attempting url 38 of 50\n",
      "DEBUG:2020-07-02 17:58:04,056:arg_mine.api.classify: Attempting url 39 of 50\n",
      "DEBUG:2020-07-02 17:58:06,066:arg_mine.api.classify: Attempting url 40 of 50\n",
      "DEBUG:2020-07-02 17:58:07,913:arg_mine.api.classify: Attempting url 41 of 50\n",
      "DEBUG:2020-07-02 17:58:09,378:arg_mine.api.classify: Attempting url 42 of 50\n",
      "DEBUG:2020-07-02 17:58:10,594:arg_mine.api.classify: Attempting url 43 of 50\n",
      "DEBUG:2020-07-02 17:58:11,610:arg_mine.api.classify: Attempting url 44 of 50\n",
      "DEBUG:2020-07-02 17:58:12,985:arg_mine.api.classify: Attempting url 45 of 50\n",
      "DEBUG:2020-07-02 17:58:14,248:arg_mine.api.classify: Attempting url 46 of 50\n",
      "DEBUG:2020-07-02 17:58:17,026:arg_mine.api.classify: Attempting url 47 of 50\n",
      "DEBUG:2020-07-02 17:58:18,533:arg_mine.api.classify: Attempting url 48 of 50\n",
      "DEBUG:2020-07-02 17:58:20,428:arg_mine.api.classify: Attempting url 49 of 50\n",
      "DEBUG:2020-07-02 17:58:27,402:arg_mine.api.classify: Attempting url 50 of 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration took 76.6 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "doc_list, sentence_list, refused_doc_list = classify.collect_sentences_by_topic(topic, url_df.content_url.values[:num_docs])\n",
    "\n",
    "print(\"iteration took {:.3} s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:2020-07-02 21:14:13,966:arg_mine.api.classify: >>>> starting doc extraction\n",
      "DEBUG:2020-07-02 21:14:31,744:arg_mine.api.classify: iteration 0 took 17.777 s (10 docs)\n",
      "DEBUG:2020-07-02 21:14:49,410:arg_mine.api.classify: iteration 1 took 17.664 s (10 docs)\n",
      "DEBUG:2020-07-02 21:15:11,633:arg_mine.api.classify: iteration 2 took 22.222 s (10 docs)\n",
      "DEBUG:2020-07-02 21:15:31,340:arg_mine.api.classify: iteration 3 took 19.705 s (10 docs)\n",
      "DEBUG:2020-07-02 21:15:59,693:arg_mine.api.classify: iteration 4 took 28.352 s (10 docs)\n",
      "DEBUG:2020-07-02 21:15:59,694:arg_mine.api.classify: 50 URLs took 105.729 s\n",
      "ERROR:2020-07-02 21:15:59,697:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,699:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,701:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,702:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,704:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,705:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,706:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,709:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,716:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n",
      "ERROR:2020-07-02 21:15:59,719:arg_mine.api.classify: 400 : {'error': 'Website could not be crawled or returned an empty result. Please contact an administrator.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration took 1.06e+02 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "responses = classify.fetch_concurrent(topic, url_list = url_df.content_url.values[:num_docs], chunk_size=10)\n",
    "docs_df, sentences_df, missing_urls = classify.process_responses(responses)\n",
    "\n",
    "print(\"iteration took {:.3} s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
